# ğŸ“š Undre GrÃ¤ns, PrioritetskÃ¶, Heapsort, Balanserade BST & Intro Grafer
## Komplett Sammanfattning: Avsnitt 2.2 (Prop I & J), 2.4, 3.3, 3.4 (fÃ¶rdjupning), 4.1

**Baserat pÃ¥:** Sedgewick & Wayne: Algorithms 4th Edition
**Komplement till:** Tidigare sammanfattningar av kap 2.2â€“2.3 och kap 3.1, 3.2, 3.4

---

# Del 1: Undre GrÃ¤ns fÃ¶r JÃ¤mfÃ¶relsebaserad Sortering (2.2, Prop I & J)

---

## ğŸ§  Problemets Komplexitet: Tre Centrala Begrepp

FÃ¶relÃ¤sningen introducerar ett tankesÃ¤tt som gÃ¥r *bortom* enskilda algoritmer. IstÃ¤llet fÃ¶r att frÃ¥ga "hur snabb Ã¤r *denna* algoritm?" frÃ¥gar vi: "hur snabbt *kan* sorteringsproblemet lÃ¶sas?"

**Ã–vre grÃ¤ns** anger vad vi *kan* uppnÃ¥. Den ges av en konkret algoritm â€” t.ex. mergesort visar att sortering gÃ¥r i ~N lg N jÃ¤mfÃ¶relser. Det Ã¤r som att sÃ¤ga: "Kolla, jag hittade en vÃ¤g upp pÃ¥ berget som tar 3 timmar, sÃ¥ det gÃ¥r *minst* sÃ¥ snabbt."

**Undre grÃ¤ns** anger vad som Ã¤r *omÃ¶jligt att slÃ¥*. Den mÃ¥ste bevisas fÃ¶r *alla* tÃ¤nkbara algoritmer, inte bara de vi kÃ¤nner till. Det Ã¤r som att bevisa att *ingen* vÃ¤g upp pÃ¥ berget kan ta mindre Ã¤n 2.5 timmar.

**Optimal algoritm** uppnÃ¥s nÃ¤r Ã¶vre och undre grÃ¤ns mÃ¶ts. DÃ¥ vet vi att ingen fÃ¶rbÃ¤ttring Ã¤r mÃ¶jlig (inom modellen).

---

## ğŸŒ³ BeslutstrÃ¤dsargumentet: Bevis fÃ¶r Proposition I

### BevisidÃ©n i Tre Steg

Vi vill visa att *varje* jÃ¤mfÃ¶relsebaserad sorteringsalgoritm mÃ¥ste gÃ¶ra minst ~N lg N jÃ¤mfÃ¶relser i vÃ¤rsta fall. Tricket Ã¤r att modellera *vilken som helst* sÃ¥dan algoritm som ett binÃ¤rt beslutstrÃ¤d.

**Steg 1: Varje algoritm motsvarar ett binÃ¤rt trÃ¤d**

Varje jÃ¤mfÃ¶relsebaserad algoritm kan beskrivas som en sekvens av ja/nej-frÃ¥gor: "Ã„r a[i] < a[j]?" Varje sÃ¥dant beslut grenar till vÃ¤nster (ja) eller hÃ¶ger (nej). Resultatet Ã¤r ett binÃ¤rt trÃ¤d dÃ¤r:

- Varje **intern nod** representerar en jÃ¤mfÃ¶relse (t.ex. "a[0] < a[1]?")
- Varje **lÃ¶v** representerar en slutgiltig ordning av elementen
- Varje **vÃ¤g frÃ¥n rot till lÃ¶v** Ã¤r den sekvens av jÃ¤mfÃ¶relser algoritmen gÃ¶r fÃ¶r en viss indata

```
                    a[0]:a[1]
                   /          \
              a[1]:a[2]      a[0]:a[2]
             /       \       /       \
          0,1,2   a[0]:a[2] a[1]:a[2]  2,1,0
                  /     \    /     \
               0,2,1  2,0,1 1,0,2  1,2,0
```

**Steg 2: TrÃ¤det mÃ¥ste ha minst N! lÃ¶v**

Det finns N! = N Ã— (Nâˆ’1) Ã— (Nâˆ’2) Ã— ... Ã— 1 olika permutationer av N distinkta element. Algoritmen mÃ¥ste kunna skilja mellan *alla* dessa â€” annars finns en permutation den inte klarar. AlltsÃ¥ krÃ¤vs minst N! lÃ¶v.

**Steg 3: HÃ¶jden begrÃ¤nsar antalet jÃ¤mfÃ¶relser**

Ett binÃ¤rt trÃ¤d med hÃ¶jd h har *hÃ¶gst* 2^h lÃ¶v (det fullstÃ¤ndiga trÃ¤det). Kombinerar vi:

```
  2^h â‰¥ N!          (antal lÃ¶v â‰¥ N!)
  
  h â‰¥ lg(N!)        (ta logaritm av bÃ¥da sidor)
  
  h â‰¥ lg(N!) ~ N lg N    (Stirlings approximation)
```

Stirlings formel ger: lg(N!) = lg(1) + lg(2) + ... + lg(N) ~ N lg N

### Proposition I (Bokens formulering)

> **Proposition I:** Ingen jÃ¤mfÃ¶relsebaserad sorteringsalgoritm kan garantera att sortera N element med fÃ¤rre Ã¤n lg(N!) ~ N lg N jÃ¤mfÃ¶relser.

**VarfÃ¶r detta Ã¤r sÃ¥ kraftfullt:** Beviset sÃ¤ger ingenting om *vilken* algoritm vi anvÃ¤nder. Det gÃ¤ller fÃ¶r alla mÃ¶jliga algoritmer som nÃ¥gon nÃ¥gonsin skulle kunna uppfinna, sÃ¥ lÃ¤nge de baseras pÃ¥ parvis jÃ¤mfÃ¶relser. Du kan alltsÃ¥ inte hitta en jÃ¤mfÃ¶relsebaserad algoritm som alltid klarar sig med t.ex. 0.5 Â· N lg N jÃ¤mfÃ¶relser.

---

## âœ… Proposition J: Mergesort Ã„r Optimal

> **Proposition J:** Mergesort Ã¤r en asymptotiskt optimal jÃ¤mfÃ¶relsebaserad sorteringsalgoritm.

**Bevis:** Mergesort anvÃ¤nder hÃ¶gst ~N lg N jÃ¤mfÃ¶relser i vÃ¤rsta fall (Proposition H frÃ¥n kap 2.2). Proposition I sÃ¤ger att varje algoritm behÃ¶ver minst ~N lg N. Eftersom Ã¶vre och undre grÃ¤ns bÃ¥da Ã¤r ~N lg N, Ã¤r mergesort optimal.

### BegrÃ¤nsningar i Optimaliteten

Boken betonar att Proposition J *inte* betyder att mergesort Ã¤r det bÃ¤sta valet i alla situationer:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VARFÃ–R MERGESORTS OPTIMALITET HAR BEGRÃ„NSNINGAR                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. Mergesort Ã¤r INTE optimal avseende minnesanvÃ¤ndning             â”‚
â”‚     (krÃ¤ver O(N) extra utrymme)                                    â”‚
â”‚                                                                     â”‚
â”‚  2. VÃ¤rsta fallet kanske sÃ¤llan intrÃ¤ffar i praktiken              â”‚
â”‚     (quicksort slÃ¥r mergesort i snitt)                              â”‚
â”‚                                                                     â”‚
â”‚  3. Andra operationer (array-Ã¥tkomster) kan dominera               â”‚
â”‚     (heapsort har dÃ¥ligt cache-beteende)                            â”‚
â”‚                                                                     â”‚
â”‚  4. Man kan sortera UTAN jÃ¤mfÃ¶relser!                               â”‚
â”‚     (radix sort, bucket sort â€” O(N) med begrÃ¤nsade nycklar)         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sorteringsalgoritmer i Perspektiv (frÃ¥n fÃ¶relÃ¤sningen)

FÃ¶relÃ¤sningen kategoriserar algoritmer efter *strukturen* pÃ¥ deras arbete:

- **LinjÃ¤rt arbete Ã— N gÃ¥nger â†’ O(NÂ²):** selection sort, insertion sort
- **LinjÃ¤rt arbete Ã— lg N gÃ¥nger â†’ O(N lg N):** mergesort, quicksort
- **Logaritmiskt arbete Ã— N gÃ¥nger â†’ O(N lg N):** heapsort
- **LinjÃ¤rt arbete Ã— konstant antal gÃ¥nger â†’ O(N):** bucket sort, radix sort (ej jÃ¤mfÃ¶relsebaserade)

> ğŸ”‘ **Nyckelinsikt frÃ¥n fÃ¶relÃ¤sningen:** Om man tillÃ¥ter *alla* CPU-operationer (inte bara jÃ¤mfÃ¶relser) finns det algoritmer som slÃ¥r N lg N! Arne Andersson (svensk forskare) har visat en garanterad O(N log log N)-algoritm, och Mikkel Thorup visade fÃ¶rvÃ¤ntad O(N âˆš(log log N)).

---

# Del 2: PrioritetskÃ¶ och BinÃ¤r Heap (Avsnitt 2.4)

---

## ğŸ¯ VarfÃ¶r BehÃ¶vs PrioritetskÃ¶er?

En prioritetskÃ¶ Ã¤r en abstrakt datastruktur som lÃ¶ser ett fundamentalt problem: **hur hanterar vi en dynamisk samling dÃ¤r vi stÃ¤ndigt vill ta ut det viktigaste (stÃ¶rsta/minsta) elementet?**

TÃ¤nk pÃ¥ det sÃ¥ hÃ¤r: en vanlig kÃ¶ ger dig det *Ã¤ldsta* elementet, en stack ger dig det *nyaste*. Men ibland vill du det *viktigaste* â€” och vad som Ã¤r "viktigast" kan fÃ¶rÃ¤ndras allteftersom nya element tillkommer.

**Praktiska tillÃ¤mpningar:**

- **Operativsystem:** Processer med hÃ¶gst prioritet kÃ¶rs fÃ¶rst
- **HÃ¤ndelsesimulering:** NÃ¤sta hÃ¤ndelse i tidsordning
- **Grafalgoritmer:** Dijkstras kortaste vÃ¤g, Prims MST (kapitel 4)
- **Datakomprimering:** Huffman-kodning (kapitel 5)
- **TopM-problemet:** Hitta de M stÃ¶rsta bland en strÃ¶m av N element (N kan vara enormt)

### API: MaxPQ

```java
public class MaxPQ<Key extends Comparable<Key>>
    MaxPQ()                // Skapa tom prioritetskÃ¶
    MaxPQ(int maxN)        // Skapa med initial kapacitet
    void insert(Key v)     // SÃ¤tt in element
    Key max()              // Returnera stÃ¶rsta
    Key delMax()           // Ta bort och returnera stÃ¶rsta
    boolean isEmpty()      // Ã„r kÃ¶n tom?
    int size()             // Antal element
```

> ğŸ’¡ **MinPQ** fungerar identiskt men med omvÃ¤nda jÃ¤mfÃ¶relser â€” bara att vÃ¤nda `less()` till `greater()`.

---

## ğŸ“Š ElementÃ¤ra Implementationer och Deras Brister

Innan vi kommer till heap-lÃ¶sningen, lÃ¥t oss fÃ¶rstÃ¥ *varfÃ¶r* den behÃ¶vs genom att se vad som hÃ¤nder med naiva lÃ¶sningar:

**Osorterad array** (lat approach â€” skjut upp arbetet):
```java
// insert(): O(1) â€” bara lÃ¤gg till sist
pq[N++] = x;

// delMax(): O(N) â€” mÃ¥ste skanna hela arrayen
int max = 0;
for (int i = 1; i < N; i++)
    if (less(max, i)) max = i;
exch(max, N-1);
return pq[--N];
```

**Sorterad array** (ivrig approach â€” gÃ¶r arbetet direkt):
- `insert()`: O(N) â€” mÃ¥ste skifta element fÃ¶r att hÃ¥lla ordning
- `delMax()`: O(1) â€” ta sista elementet

**BST** fungerar men: trÃ¤dets hÃ¶jd kan bli linjÃ¤r utan balansering, och BST kan sÃ¶ka *vilken* nyckel som helst â€” vi behÃ¶ver bara den stÃ¶rsta. Det finns en enklare och billigare struktur fÃ¶r just detta!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRESTANDAJÃ„MFÃ–RELSE FÃ–R PRIORITETSKÃ–ER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Implementation       â”‚  insert()    â”‚  delMax()                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Osorterad array      â”‚  O(1)        â”‚  O(N)                       â”‚
â”‚  Sorterad array       â”‚  O(N)        â”‚  O(1)                       â”‚
â”‚  BinÃ¤r heap           â”‚  O(lg N)     â”‚  O(lg N)                    â”‚
â”‚  (OmÃ¶jlig) drÃ¶mmen    â”‚  O(1)        â”‚  O(1)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Heap-ordnat Komplett BinÃ¤rtrÃ¤d

### TvÃ¥ NyckelidÃ©er

**IdÃ© 1: Heap-ordning** â€” Varje nod har en nyckel som Ã¤r â‰¥ nycklarna hos bÃ¥da barnen. Det betyder att roten *alltid* innehÃ¥ller det stÃ¶rsta elementet.

> **Proposition O:** Det stÃ¶rsta elementet i ett heap-ordnat binÃ¤rtrÃ¤d finns i roten.

**IdÃ© 2: Komplett binÃ¤rtrÃ¤d** â€” TrÃ¤det Ã¤r fyllt nivÃ¥ fÃ¶r nivÃ¥, uppifrÃ¥n och ner, vÃ¤nster till hÃ¶ger. Den enda nivÃ¥n som kan vara ofullstÃ¤ndig Ã¤r den sista.

Kombinationen gÃ¶r att vi kan representera trÃ¤det *utan pekare*, bara som en array!

### Array-representation: Elegant Aritmetik

IstÃ¤llet fÃ¶r att lagra vÃ¤nster/hÃ¶ger-pekare i varje nod, lÃ¤gger vi noderna i en array i **nivÃ¥ordning** (level order). Position 1 Ã¤r roten, position 0 lÃ¤mnas tom:

```
  Index:    0   1   2   3   4   5   6   7   8   9  10  11
  Array:    -   T   S   R   P   N   O   A   E   I   H   G

  TrÃ¤dvy:
                         T (1)
                       /      \
                   S (2)       R (3)
                  /    \      /    \
              P (4)  N (5) O (6)  A (7)
             / \    / \
          E(8) I(9) H(10) G(11)
```

**Navigering utan pekare:**

| Operation | Formel | Exempel (frÃ¥n nod k=3, "R") |
|---|---|---|
| FÃ¶rÃ¤lder till k | âŒŠk/2âŒ‹ | âŒŠ3/2âŒ‹ = 1 â†’ "T" |
| VÃ¤nster barn till k | 2k | 2Ã—3 = 6 â†’ "O" |
| HÃ¶ger barn till k | 2k + 1 | 2Ã—3+1 = 7 â†’ "A" |

> **Proposition P:** HÃ¶jden pÃ¥ ett komplett binÃ¤rtrÃ¤d med N noder Ã¤r âŒŠlg NâŒ‹.

Detta Ã¤r nyckeln till logaritmisk prestanda â€” vi behÃ¶ver aldrig gÃ¥ lÃ¤ngre Ã¤n ~lg N steg.

---

## â¬†ï¸â¬‡ï¸ Swim och Sink: Heap-ordningens VÃ¤ktare

Alla heap-operationer bygger pÃ¥ tvÃ¥ primitiver som reparerar heap-ordningen nÃ¤r den bryts. TÃ¤nk pÃ¥ dem som "gravitationskrafter" i trÃ¤det.

### Swim (Bottom-up reheapify)

**NÃ¤r:** En nod har *stÃ¶rre* nyckel Ã¤n sin fÃ¶rÃ¤lder (bryter heap-ordningen "underifrÃ¥n").
**Strategi:** Byt med fÃ¶rÃ¤ldern, upprepa tills ordningen gÃ¤ller.

```java
private void swim(int k) {
    while (k > 1 && less(k/2, k)) {  // Medan fÃ¶rÃ¤ldern Ã¤r mindre
        exch(k, k/2);                 // Byt med fÃ¶rÃ¤lder
        k = k/2;                      // GÃ¥ uppÃ¥t
    }
}
```

**Visualisering â€” "S" simmar upp:**
```
  FÃ–RE:                    EFTER:
       S                        T
      / \                      / \
     P    R          â†’        S    R
    / \                      / \
   G   T â† bryter!         G   P
       (T > P)
```

**Tid:** O(lg N) â€” hÃ¶gst hÃ¶jden av trÃ¤det.

### Sink (Top-down reheapify)

**NÃ¤r:** En nod har *mindre* nyckel Ã¤n nÃ¥got av sina barn (bryter heap-ordningen "ovanifrÃ¥n").
**Strategi:** Byt med det *stÃ¶rre* barnet, upprepa nedÃ¥t.

```java
private void sink(int k) {
    while (2*k <= N) {                    // Medan noden har barn
        int j = 2*k;                      // VÃ¤nster barn
        if (j < N && less(j, j+1)) j++;   // VÃ¤lj det STÃ–RRE barnet
        if (!less(k, j)) break;           // Ordningen ok? Sluta
        exch(k, j);                        // Byt med stÃ¶rre barnet
        k = j;                            // GÃ¥ nedÃ¥t
    }
}
```

**VarfÃ¶r byta med det *stÃ¶rre* barnet?** Om vi byter med det mindre, kan det nya barnets nyckel fortfarande vara mindre Ã¤n det andra barnet â€” och heap-ordningen skulle brytas dÃ¤r istÃ¤llet!

**Visualisering â€” "H" sjunker ner:**
```
  FÃ–RE:                     EFTER sink(2):
       T                          T
      / \                        / \
     H    R         â†’           S    R
    / \                        / \
   P   S â† S > H!            P   N
  / \  / \                   / \  / \
 E  I N  G                 E  I H  G
```

**Tid:** O(lg N) â€” hÃ¶gst hÃ¶jden av trÃ¤det. Varje nivÃ¥ krÃ¤ver 2 jÃ¤mfÃ¶relser (en fÃ¶r att hitta det stÃ¶rre barnet, en fÃ¶r att jÃ¤mfÃ¶ra med noden).

---

## ğŸ”§ Insert och DelMax: Heapens Huvudoperationer

### Insert: LÃ¤gg till sist och simma upp

```java
public void insert(Key x) {
    pq[++N] = x;    // LÃ¤gg till lÃ¤ngst ner till hÃ¶ger (sista positionen)
    swim(N);         // LÃ¥t elementet simma upp till rÃ¤tt position
}
```

**Steg-fÃ¶r-steg:**
1. Ã–ka N, placera det nya elementet pÃ¥ position N
2. Det kan bryta heap-ordningen (vara stÃ¶rre Ã¤n sin fÃ¶rÃ¤lder)
3. Anropa `swim()` fÃ¶r att fixa â€” elementet bubblar uppÃ¥t tills det hamnar rÃ¤tt

**Tid:** HÃ¶gst 1 + lg N jÃ¤mfÃ¶relser (Proposition Q).

### DelMax: Byt toppen med botten, sjunk ner

```java
public Key delMax() {
    Key max = pq[1];       // Spara det stÃ¶rsta (roten)
    exch(1, N--);          // Byt rot med sista elementet, minska storlek
    sink(1);               // Det (sannolikt lilla) elementet sjunker till rÃ¤tt plats
    pq[N+1] = null;        // Undvik minneslÃ¤ckage (loitering)
    return max;
}
```

**Steg-fÃ¶r-steg:**
1. Roten (position 1) Ã¤r alltid max â€” spara den
2. Flytta det sista elementet (lÃ¤ngst ner till hÃ¶ger) till roten
3. Minska N
4. Det nya rotelementet Ã¤r sannolikt fÃ¶r litet â†’ `sink()` fixar det
5. Nolla den gamla positionen sÃ¥ att garbage collector kan frigÃ¶ra minnet

**Tid:** HÃ¶gst 2 lg N jÃ¤mfÃ¶relser (Proposition Q) â€” `sink()` gÃ¶r 2 jÃ¤mfÃ¶relser per nivÃ¥.

### Proposition Q (formellt)

> **Proposition Q:** I en prioritetskÃ¶ med N nycklar krÃ¤ver heap-algoritmerna hÃ¶gst 1 + lg N jÃ¤mfÃ¶relser fÃ¶r `insert` och hÃ¶gst 2 lg N jÃ¤mfÃ¶relser fÃ¶r `remove the maximum`.

---

## ğŸ  Heapkonstruktion: Bygg en Heap i LinjÃ¤r Tid!

Man kan bygga en heap genom att upprepa `insert()` N gÃ¥nger â†’ O(N lg N). Men det finns ett bÃ¤ttre sÃ¤tt!

### Bottom-up Konstruktion med Sink

**IdÃ©n:** Fyll arrayen med elementen i godtycklig ordning. KÃ¶r sedan `sink()` pÃ¥ alla icke-lÃ¶v-noder, nerifrÃ¥n och upp:

```java
for (int k = N/2; k >= 1; k--)
    sink(a, k, N);
```

**VarfÃ¶r bÃ¶rja vid N/2?** Noderna N/2+1 till N Ã¤r alla lÃ¶v (de har inga barn). Ett lÃ¶v Ã¤r automatiskt en korrekt heap av storlek 1 â€” inget arbete behÃ¶vs.

**VarfÃ¶r nerifrÃ¥n och upp?** NÃ¤r vi kÃ¶r `sink(k)` har barnen till k *redan* fixats (de har lÃ¤gre index). SÃ¥ `sink()` utgÃ¥r frÃ¥n att subtrÃ¤den redan Ã¤r korrekta heapar.

### Proposition R: LinjÃ¤r Tid

> **Proposition R:** Sink-baserad heapkonstruktion anvÃ¤nder fÃ¤rre Ã¤n 2N jÃ¤mfÃ¶relser och fÃ¤rre Ã¤n N byten.

**BevisidÃ© (frÃ¥n fÃ¶relÃ¤sningen):**

Nyckeln Ã¤r att *de flesta noder sitter nÃ¤ra botten* och behÃ¶ver bara sjunka en kort strÃ¤cka:

```
  Djup h (lÃ¶v):     N/2 noder, 0 jÃ¤mfÃ¶relser (skippar dem)
  Djup h-1:         N/4 noder, hÃ¶gst 2 jÃ¤mfÃ¶relser var
  Djup h-2:         N/8 noder, hÃ¶gst 4 jÃ¤mfÃ¶relser var
  Djup h-3:         N/16 noder, hÃ¶gst 6 jÃ¤mfÃ¶relser var
  ...
  Djup h-k:         N/2^(k+1) noder, hÃ¶gst 2k jÃ¤mfÃ¶relser var
```

Totalt antal jÃ¤mfÃ¶relser â‰¤ NÂ·(2/4 + 4/8 + 6/16 + 8/32 + ...) = N Â· Î£(2k/2^(k+1)) = **2N**

Serien konvergerar (WolframAlpha bekrÃ¤ftar Î£ kÂ·2^(-k) = 2), sÃ¥ hela konstruktionen kostar ~2N jÃ¤mfÃ¶relser. Det Ã¤r *linjÃ¤rt* â€” mycket bÃ¤ttre Ã¤n O(N lg N)!

> ğŸ¯ **Intuition:** HÃ¤lften av noderna gÃ¶r 0 arbete, en fjÃ¤rdedel gÃ¶r ~2, en Ã¥ttondel gÃ¶r ~4... Det totala arbetet domineras av de mÃ¥nga enkla fallen nÃ¤ra botten.

---

## ğŸ“ˆ Heapsort (Algoritm 2.7): Sortering med Heap

Heapsort kombinerar heapkonstruktion med upprepade `delMax()` till en elegant in-place sorteringsalgoritm.

### TvÃ¥ Faser

**Fas 1: Heapkonstruktion** â€” Omorganisera arrayen till en max-heap.
**Fas 2: Sortdown** â€” Plocka ut det stÃ¶rsta elementet ur heapen, placera det i sin slutliga position.

```java
public static void sort(Comparable[] a) {
    int N = a.length;
    
    // Fas 1: Bygg heap (nerifrÃ¥n och upp)
    for (int k = N/2; k >= 1; k--)
        sink(a, k, N);
    
    // Fas 2: Sortdown (upprepad delMax)
    while (N > 1) {
        exch(a, 1, N--);   // Byt rot (max) med sista elementet
        sink(a, 1, N);     // Reparera heapen
    }
}
```

### Detaljerad SpÃ¥rning

```
  Indata:     S O R T E X A M P L E

  FAS 1 â€” Heapkonstruktion (sink-baserad):
  
  k=5: sink(5,11)  â†’  S O R T L X A M P E E
  k=4: sink(4,11)  â†’  S O R T L X A M P E E   (ingen fÃ¶rÃ¤ndring)
  k=3: sink(3,11)  â†’  S O X T L R A M P E E
  k=2: sink(2,11)  â†’  S T X P L R A M O E E
  k=1: sink(1,11)  â†’  X T S P L R A M O E E   â† heap-ordnad!

  FAS 2 â€” Sortdown:
  
  exch(1,11), sink(1,10) â†’  T P S O L R A M E E | X
  exch(1,10), sink(1,9)  â†’  S P R O L E A M E | T X
  exch(1,9),  sink(1,8)  â†’  R P E O L E A M | S T X
  ...                     â†’  ...
  Slutresultat:              A E E L M O P R S T X â† sorterat!
```

**Vad hÃ¤nder i varje steg av sortdown?**
1. `exch(1, N--)`: Det stÃ¶rsta elementet (roten) byter plats med det sista osorterade. Det hamnar i sin slutgiltiga, korrekta position.
2. `sink(1, N)`: Heapen har krympt med ett element. Det element som flyttades till roten "sjunker" ner till rÃ¤tt plats.

### Proposition S: Heapsorts Prestanda

> **Proposition S:** Heapsort anvÃ¤nder fÃ¤rre Ã¤n 2N lg N + 2N jÃ¤mfÃ¶relser (och hÃ¤lften sÃ¥ mÃ¥nga byten).

Bevis: 2N fÃ¶r heapkonstruktionen (Prop R) + 2 lg N per delMax Ã— N element = 2N lg N.

### Heapsort i det Stora Perspektivet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HEAPSORT: UNIK POSITION BLAND SORTERINGSALGORITMER                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  âœ… Garanterad O(N lg N) â€” ingen dÃ¥lig indata kan gÃ¶ra det vÃ¤rre    â”‚
â”‚  âœ… In-place â€” O(1) extra minne (bara ett par temporÃ¤ra variabler) â”‚
â”‚  âœ… Enda algoritmen som Ã¤r optimal i BÃ…DE tid OCH minne!           â”‚
â”‚                                                                     â”‚
â”‚  âŒ Inte stabil (Ã¤ndrar ordning fÃ¶r element med lika nycklar)       â”‚
â”‚  âŒ DÃ¥ligt cache-beteende (jÃ¤mfÃ¶relser hoppar runt i arrayen)      â”‚
â”‚  âŒ LÃ¥ngsammare inre loop Ã¤n quicksort i praktiken                 â”‚
â”‚                                                                     â”‚
â”‚  ANVÃ„NDNING: InbÃ¤ddade system och realtidssystem dÃ¤r                â”‚
â”‚  minnesgaranti och tidsgaranti Ã¤r viktigare Ã¤n rÃ¥hastighet         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Floyds Optimering (frivillig fÃ¶rdjupning)

Floyd observerade 1964 att de flesta element som sÃ¤tts in vid roten under sortdown sjunker *hela vÃ¤gen ner* till botten. Hans idÃ©: sjunk noden Ã¤nda till botten utan att kontrollera om den nÃ¥tt rÃ¤tt plats, och simma sedan upp frÃ¥n botten. Detta halverar antalet jÃ¤mfÃ¶relser asymptotiskt (nÃ¤ra mergesorts nivÃ¥), men krÃ¤ver mer bokfÃ¶ring och lÃ¶nar sig frÃ¤mst nÃ¤r jÃ¤mfÃ¶relser Ã¤r dyra (t.ex. lÃ¥nga strÃ¤ngar).

---

## ğŸ¯ Sammanfattning: Sorteringsalgoritmer â€” Komplett Ã–versikt

Nu nÃ¤r vi har sett *alla* jÃ¤mfÃ¶relsebaserade sorteringsalgoritmer kan vi sammanfatta:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KOMPLETT SORTERINGSTABELL                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Algoritm     â”‚BÃ¤sta fallâ”‚Genomsnittâ”‚VÃ¤rsta   â”‚Minne   â”‚Stabil? â”‚In-placeâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Selection sort â”‚ Â½NÂ²     â”‚ Â½NÂ²     â”‚ Â½NÂ²     â”‚ O(1)   â”‚ Nej    â”‚ Ja     â”‚
â”‚Insertion sort â”‚ N       â”‚ Â¼NÂ²     â”‚ Â½NÂ²     â”‚ O(1)   â”‚ Ja     â”‚ Ja     â”‚
â”‚Shellsort     â”‚ N       â”‚ ?       â”‚ ?       â”‚ O(1)   â”‚ Nej    â”‚ Ja     â”‚
â”‚Mergesort     â”‚ Â½NlgN   â”‚ NlgN    â”‚ NlgN    â”‚ O(N)   â”‚ Ja     â”‚ Nej    â”‚
â”‚Quicksort     â”‚ NlgN    â”‚ 1.39NlgNâ”‚ Â½NÂ²     â”‚ O(lgN) â”‚ Nej    â”‚ Ja     â”‚
â”‚3-way QS      â”‚ N       â”‚ 1.39NlgNâ”‚ Â½NÂ²     â”‚ O(lgN) â”‚ Nej    â”‚ Ja     â”‚
â”‚Heapsort      â”‚ NlgN    â”‚ 2NlgN   â”‚ 2NlgN   â”‚ O(1)   â”‚ Nej    â”‚ Ja     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Undre grÃ¤ns (alla jÃ¤mfÃ¶relsebaserade): ~ N lg N                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Del 3: Balanserade SÃ¶ktrÃ¤d â€” 2-3-trÃ¤d och RÃ¶d-Svarta BST (Avsnitt 3.3)

---

## ğŸ¯ Problemet: VarfÃ¶r Vanliga BST Inte RÃ¤cker

I den tidigare sammanfattningen (kap 3.2) sÃ¥g vi att BST ger utmÃ¤rkt *genomsnittlig* prestanda (~1.39 lg N jÃ¤mfÃ¶relser). Men i *vÃ¤rsta fall* â€” t.ex. om nycklar sÃ¤tts in i sorterad ordning â€” degenererar trÃ¤det till en lÃ¤nkad lista med N hÃ¶jd.

**Exempel: InsÃ¤ttning av A, B, C, D, E i ordning**
```
  A
   \
    B
     \
      C
       \
        D
         \
          E    â† hÃ¶jd = N-1, alla operationer O(N)!
```

Vi vill ha **garanterad logaritmisk prestanda** oavsett insÃ¤ttningsordning.

---

## ğŸŒ³ 2-3-TrÃ¤d: Den Konceptuella Grunden

### Definition

Ett **2-3-trÃ¤d** Ã¤r antingen tomt eller ett trÃ¤d som har tvÃ¥ typer av noder:

**2-nod:** En nyckel, tvÃ¥ barn-lÃ¤nkar (precis som vanlig BST-nod)
```
    [K]
   /   \
 <K     >K
```

**3-nod:** TvÃ¥ nycklar, tre barn-lÃ¤nkar
```
    [E  K]
   /   |   \
 <E  E..K   >K
```

**AvgÃ¶rande egenskap:** Alla null-lÃ¤nkar (lÃ¶v) befinner sig pÃ¥ **samma djup**. TrÃ¤det har alltsÃ¥ *perfekt balans*.

### SÃ¶kning i 2-3-TrÃ¤d

SÃ¶kning fungerar som i BST, men med fler jÃ¤mfÃ¶relser per nod:

**I en 2-nod:** JÃ¤mfÃ¶r med nyckeln, gÃ¥ vÃ¤nster eller hÃ¶ger.
**I en 3-nod:** JÃ¤mfÃ¶r med *bÃ¥da* nycklarna â€” gÃ¥ till vÃ¤nster, mitten eller hÃ¶ger barn.

### InsÃ¤ttning i 2-3-TrÃ¤d: Lokala Transformationer

Nyckelprincipen: vi sÃ¤tter aldrig in en nod som ett nytt lÃ¶v (som i BST). IstÃ¤llet *absorberar* vi nyckeln i en befintlig nod vid botten.

**Fall 1: InsÃ¤ttning i en 2-nod â†’ blir en 3-nod**

Det finns plats! Bara lÃ¤gg till nyckeln.
```
  SÃ¶k ner till [K], vill sÃ¤tta in L:
  
  [K] â†’ [K L]     (2-nod blir 3-nod)
```

**Fall 2: InsÃ¤ttning i en 3-nod â†’ temporÃ¤r 4-nod â†’ split**

Det finns *inte* plats. Vi skapar en temporÃ¤r 4-nod och *splittar* den:

```
  SÃ¶k ner till [E K], vill sÃ¤tta in H:
  
  1. [E K] + H â†’ [E H K]   (temporÃ¤r 4-nod)
  
  2. Splitta: mittnyckel (H) skickas UPPÃ…T till fÃ¶rÃ¤ldern
  
     [H]
    /   \
  [E]   [K]     (tre 2-noder)
```

Om fÃ¶rÃ¤ldern *ocksÃ¥* var en 3-nod, upprepas processen uppÃ¥t. I vÃ¤rsta fall bubblar en split hela vÃ¤gen upp till roten. Om roten splittas, skapas en ny rot och **trÃ¤dhÃ¶jden Ã¶kar med exakt 1**.

> ğŸ¯ **Fundamental insikt:** 2-3-trÃ¤d *vÃ¤xer uppÃ¥t* (frÃ¥n roten), inte nedÃ¥t som BST! Det Ã¤r dÃ¤rfÃ¶r balansen bevaras â€” alla lÃ¶v pÃ¥verkas lika mycket av en ny nivÃ¥.

### HÃ¶jdgaranti

> **Proposition (3.3.4):** HÃ¶jden pÃ¥ ett 2-3-trÃ¤d med N nycklar Ã¤r mellan âŒŠlogâ‚ƒ NâŒ‹ â‰ˆ 0.63 lg N (alla 3-noder) och âŒŠlg NâŒ‹ (alla 2-noder).

Ã„ven i vÃ¤rsta fall Ã¤r hÃ¶jden logaritmisk!

---

## ğŸ”´âš« RÃ¶d-Svarta BST: 2-3-TrÃ¤d i BST-fÃ¶rklÃ¤dnad

### VarfÃ¶r Inte Implementera 2-3-TrÃ¤d Direkt?

Direkt implementation av 2-3-trÃ¤d krÃ¤ver:
- TvÃ¥ olika nodtyper (2-noder och 3-noder)
- Komplicerad kod fÃ¶r att konvertera mellan dem
- MÃ¥nga specialfall

En rÃ¶d-svart BST **kodar 2-3-trÃ¤dets struktur** i ett vanligt BST genom att anvÃ¤nda lÃ¤nkfÃ¤rger istÃ¤llet.

### Kodning av 3-Noder

En **3-nod** med nycklar (a, b) representeras som *tvÃ¥ 2-noder* fÃ¶rbundna av en **rÃ¶d lÃ¤nk** som lutar Ã¥t vÃ¤nster:

```
  3-nod [a  b]          RÃ¶d-svart representation:
     /   |   \    
   <a  a..b   >b            b          ("b" Ã¤r den Ã¶vre noden)
                           / \
                     rÃ¶dâ†’ a   >b       ("a" fÃ¶rbunden med rÃ¶d lÃ¤nk)
                         / \
                       <a  a..b
```

### Tre Definierande Regler

1. **RÃ¶da lÃ¤nkar lutar Ã¥t vÃ¤nster** â€” den mindre nyckeln i en 3-nod Ã¤r alltid vÃ¤nster barn
2. **Ingen nod har tvÃ¥ rÃ¶da lÃ¤nkar kopplade till sig** â€” (det skulle motsvara en 4-nod, som inte tillÃ¥ts i ett 2-3-trÃ¤d)
3. **Perfekt svart balans** â€” varje vÃ¤g frÃ¥n rot till null-lÃ¤nk har *exakt samma* antal svarta lÃ¤nkar

### 1-1 Korrespondens: Visualisering

Om du ritar rÃ¶da lÃ¤nkar horisontellt i en rÃ¶d-svart BST, och sedan "kollapsar" par fÃ¶rbundna av rÃ¶da lÃ¤nkar, fÃ¥r du exakt motsvarande 2-3-trÃ¤d:

```
  RÃ¶d-svart BST:                   Motsvarande 2-3-trÃ¤d:
  
       M (svart)                         [E  M]
      / \                               /  |   \
    E    R (svart)                    [A C] [H] [R S]
   /â†—\    / \
  A   H  P   S                  (â†— markerar rÃ¶d lÃ¤nk)
 / \
C
```

### FÃ¤rgrepresentation i Koden

```java
private static final boolean RED   = true;
private static final boolean BLACK = false;

private class Node {
    Key key;
    Value val;
    Node left, right;
    int N;           // Antal noder i subtrÃ¤det
    boolean color;   // FÃ¤rg pÃ¥ lÃ¤nken FRÃ…N fÃ¶rÃ¤ldern
}

private boolean isRed(Node x) {
    if (x == null) return false;  // Null-lÃ¤nkar Ã¤r svarta
    return x.color == RED;
}
```

---

## ğŸ”„ Rotationer och FÃ¤rgflippar: Verktygen

Tre operationer rÃ¤cker fÃ¶r att implementera alla balanserings-transformationer:

### VÃ¤nsterrotation (rotateLeft)

RÃ¤tar upp en *hÃ¶gerlutnande* rÃ¶d lÃ¤nk:

```
  FÃ–RE:                        EFTER:
     E                            S
      \â†—                        â†—/
       S          â†’            E
      / \                     / \
    E-S  >S                 <E  E-S
```

```java
private Node rotateLeft(Node h) {
    Node x = h.right;
    h.right = x.left;
    x.left = h;
    x.color = h.color;    // Ã„rv fÃ¶rÃ¤lderns lÃ¤nkfÃ¤rg
    h.color = RED;         // h blir rÃ¶d (del av ny 3-nod)
    x.N = h.N;
    h.N = 1 + size(h.left) + size(h.right);
    return x;
}
```

### HÃ¶gerrotation (rotateRight)

RÃ¤tar upp en situation med *tvÃ¥ konsekutiva vÃ¤nsterlutnande* rÃ¶da lÃ¤nkar:

```
  FÃ–RE:                        EFTER:
       S                         E
      â†—/                          \â†—
     E            â†’                S
    / \                           / \
  <E  E-S                      E-S  >S
```

### FÃ¤rgflipp (flipColors)

Splittar en nod vars *bÃ¥da* barn har rÃ¶da lÃ¤nkar (= temporÃ¤r 4-nod):

```
  FÃ–RE (4-nod):               EFTER (split):
       E (svart)                   E (rÃ¶d â†‘ skickas till fÃ¶rÃ¤lder)
      â†—/ \â†—                       / \
     A    S    â†’                  A    S
   (rÃ¶d) (rÃ¶d)                (svart) (svart)
```

```java
private void flipColors(Node h) {
    h.color = RED;              // Skicka mittnyckeln uppÃ¥t (rÃ¶d)
    h.left.color = BLACK;       // Barnen blir svarta
    h.right.color = BLACK;
}
```

---

## ğŸ§© Put-operationen: Allt Faller pÃ¥ Plats

Den eleganta insikten: bara *tre* `if`-satser efter de rekursiva anropen balanserar hela trÃ¤det!

```java
private Node put(Node h, Key key, Value val) {
    if (h == null)  // Ny nod med rÃ¶d lÃ¤nk till fÃ¶rÃ¤ldern
        return new Node(key, val, 1, RED);
    
    // Standard BST-insÃ¤ttning
    int cmp = key.compareTo(h.key);
    if      (cmp < 0) h.left  = put(h.left,  key, val);
    else if (cmp > 0) h.right = put(h.right, key, val);
    else              h.val = val;  // Uppdatera vÃ¤rdet
    
    // â”€â”€ Balanseringsfix (3 rader!) â”€â”€
    if (isRed(h.right) && !isRed(h.left))     h = rotateLeft(h);
    if (isRed(h.left) && isRed(h.left.left))  h = rotateRight(h);
    if (isRed(h.left) && isRed(h.right))      flipColors(h);
    
    h.N = 1 + size(h.left) + size(h.right);
    return h;
}
```

**De tre fixerna i ordning:**

| Steg | Villkor | Ã…tgÃ¤rd | Syfte |
|------|---------|--------|-------|
| 1 | HÃ¶gerlutnande rÃ¶d lÃ¤nk | `rotateLeft` | RÃ¤tta till "fel" lutning |
| 2 | TvÃ¥ konsekutiva vÃ¤nsterrÃ¶da | `rotateRight` | TemporÃ¤r 4-nod â†’ balansera |
| 3 | BÃ¥da barnen rÃ¶da | `flipColors` | Splitta 4-nod, skicka nyckel uppÃ¥t |

> ğŸ¯ **Nyckelpunkt:** `get()` i en rÃ¶d-svart BST Ã¤r **exakt samma** som i en vanlig BST. FÃ¤rgerna spelar ingen roll vid sÃ¶kning â€” de behÃ¶vs bara vid insÃ¤ttning (och borttagning).

---

## ğŸ“Š Analys av RÃ¶d-Svarta BST

### Proposition G: HÃ¶jdgaranti

> **Proposition G:** HÃ¶jden pÃ¥ en rÃ¶d-svart BST med N noder Ã¤r hÃ¶gst 2 lg N.

**Bevis (skiss):** VÃ¤rsta fallet Ã¤r ett 2-3-trÃ¤d bestÃ¥ende av bara 2-noder *utom* lÃ¤ngs en vÃ¤g som har 3-noder. Den lÃ¤ngsta vÃ¤gen (med 3-noder) har dubbelt sÃ¥ mÃ¥nga BST-noder som den kortaste (bara 2-noder), vars lÃ¤ngd Ã¤r ~lg N. AlltsÃ¥ â‰¤ 2 lg N.

### Property H: Typisk Prestanda

> **Property H:** Den genomsnittliga vÃ¤glÃ¤ngden till en nod i en rÃ¶d-svart BST med N noder Ã¤r ~1.00 lg N.

I praktiken beter sig rÃ¶d-svarta BST nÃ¤stan som perfekt balanserade trÃ¤d! JÃ¤mfÃ¶rt med vanliga BST (1.39 lg N) Ã¤r detta ~28% fÃ¤rre jÃ¤mfÃ¶relser per sÃ¶kning.

### Proposition I (bokens 3.3): Logaritmisk Garanti fÃ¶r Allt

> **Proposition I:** I en rÃ¶d-svart BST tar sÃ¶kning, insÃ¤ttning, min/max, floor/ceiling, rank, select, delete min/max, delete, och range count alla **logaritmisk tid** i vÃ¤rsta fall.

**Bevis:** Alla operationer gÃ¶r arbete proportionellt mot trÃ¤dets hÃ¶jd, som Ã¤r â‰¤ 2 lg N (Prop G).

### Uppdaterad Symboltabell-kostnadsÃ¶versikt

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SYMBOLTABELLER: FULLSTÃ„NDIG KOSTNADSÃ–VERSIKT                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       â”‚ VÃ¤rsta fallâ”‚  Genomsnitt  â”‚ Genomsnittâ”‚  Ordnade â”‚
â”‚  Implementation       â”‚  sÃ¶kning   â”‚  sÃ¶kning     â”‚ insÃ¤ttningâ”‚  op.?    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Sekventiell sÃ¶kning  â”‚     N      â”‚    N/2       â”‚     N     â”‚   Nej    â”‚
â”‚  (osorterad lista)    â”‚            â”‚              â”‚           â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BinÃ¤rsÃ¶kning         â”‚   lg N     â”‚    lg N      â”‚    N      â”‚   Ja     â”‚
â”‚  (ordnad array)       â”‚            â”‚              â”‚           â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BST                  â”‚     N      â”‚  1.39 lg N   â”‚ 1.39 lg N â”‚   Ja     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RÃ¶d-svart BST        â”‚  2 lg N    â”‚  1.00 lg N   â”‚ 1.00 lg N â”‚   Ja     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Separate chaining    â”‚    N       â”‚    N/(2M)    â”‚   N/M     â”‚   Nej    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Linear probing       â”‚    N       â”‚    ~1.5      â”‚   ~2.5    â”‚   Nej    â”‚
â”‚  (Î±=0.5)              â”‚            â”‚              â”‚           â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Borttagning i RÃ¶d-Svarta BST (koncept)

Borttagning Ã¤r den mest komplicerade operationen. GrundidÃ©n (utan full implementation):

1. Vid **deleteMin**: GÃ¥ nedÃ¥t lÃ¤ngs vÃ¤nsterlÃ¤nkarna. Innan vi gÃ¥r ner, sÃ¤kerstÃ¤ll att den aktuella noden *inte* Ã¤r en 2-nod (annars kan vi inte ta bort frÃ¥n den). Vi skapar temporÃ¤ra 4-noder pÃ¥ vÃ¤gen ner genom att "lÃ¥na" nycklar frÃ¥n syskon.
2. Vid botten finns en 3-nod eller 4-nod, varifrÃ¥n vi kan ta bort minsta nyckeln utan problem.
3. PÃ¥ vÃ¤gen upp splittar vi eventuella kvarvarande 4-noder (precis som vid insÃ¤ttning).

> ğŸ’¡ **Delete** (godtycklig nyckel) anvÃ¤nder samma teknik: om nyckeln Ã¤r vid botten, ta bort direkt. Om den Ã¤r intern, ersÃ¤tt med efterfÃ¶ljaren (som i vanlig BST-delete), och gÃ¶r sedan deleteMin i hÃ¶gersubtrÃ¤det.

---

# Del 4: Hashtabeller â€” FÃ¶rdjupning (Avsnitt 3.4)

---

Den tidigare sammanfattningen tÃ¤ckte grunderna om separate chaining, linear probing, hashfunktioner, load factor och propositioner K och M. HÃ¤r fÃ¶rdjupar vi med **designmÃ¶nster, praktiska Ã¶vervÃ¤ganden, och avancerade aspekter** som inte tÃ¤cktes.

## ğŸ”¬ Hashtabell vs Balanserat BST: En Djupare JÃ¤mfÃ¶relse

I den tidigare sammanfattningen listade vi *nÃ¤r* man ska anvÃ¤nda vilken. HÃ¤r utforskar vi *varfÃ¶r* mer djupgÃ¥ende:

### Hashtabellens Fundamentala Antagande

Hashtabellens O(1)-prestanda vilar pÃ¥ **Antagande J** (uniform hashing assumption): att hashfunktionen sprider nycklarna jÃ¤mnt Ã¶ver alla positioner. I verkligheten Ã¤r detta aldrig *exakt* sant, men bra hashfunktioner approximerar det vÃ¤l.

Om antagandet *inte* gÃ¤ller (dÃ¥lig hashfunktion), kan alla nycklar hamna i samma hink â†’ O(N) per operation. Det Ã¤r samma problematik som osorterad BST! Skillnaden Ã¤r att en rÃ¶d-svart BST *garanterar* lg N oavsett input, medan en hashtabell fÃ¶rlitar sig pÃ¥ hashfunktionens kvalitet.

### Ordnade Operationer: Hashtabellens AkilleshÃ¤l

Hashtabeller kastar bort nyckelordningen vid hashning. Det gÃ¶r fÃ¶ljande operationer **omÃ¶jliga** (eller krÃ¤ver O(N)):

- `min()`, `max()` â€” mÃ¥ste skanna allt
- `floor(key)`, `ceiling(key)` â€” krÃ¤ver ordning
- `rank(key)`, `select(k)` â€” krÃ¤ver ordning
- `keys(lo, hi)` (range query) â€” krÃ¤ver ordning

> ğŸ¯ **Tumregel (uppdaterad):**
> - BehÃ¶ver du ordnade operationer? â†’ **RÃ¶d-svart BST** (eller annat balanserat trÃ¤d)
> - BehÃ¶ver du *bara* sÃ¶kning/insÃ¤ttning/borttagning och vill ha snabbast mÃ¶jligt? â†’ **Hashtabell**
> - OsÃ¤ker? â†’ BÃ¶rja med rÃ¶d-svart BST (Java: `TreeMap`) â€” det fungerar alltid bra

### Javas Inbyggda Val

Java anvÃ¤nder faktiskt bÃ¥da:
- `HashMap`: Hashtabell (separate chaining). Snabbast fÃ¶r de flesta fall.
- `TreeMap`: RÃ¶d-svart BST. StÃ¶djer ordnade operationer.
- Javas `Arrays.sort()`: AnvÃ¤nder mergesort fÃ¶r objekt (stabil), quicksort (dual-pivot) fÃ¶r primitiver.

---

## ğŸ”‘ Hashfunktioner: Praktiska Detaljer

### Konsistenskravet

Om `a.equals(b)` Ã¤r sant, **mÃ¥ste** `a.hashCode() == b.hashCode()`. Annars bryts hashtabellen! (Men det omvÃ¤nda gÃ¤ller inte: samma hashkod *kan* ge sig fÃ¶r olika objekt â€” det Ã¤r en kollision.)

### VarfÃ¶r `(key.hashCode() & 0x7fffffff) % M`?

```java
private int hash(Key key) {
    return (key.hashCode() & 0x7fffffff) % M;
}
```

- `hashCode()` returnerar en `int` (kan vara negativ!)
- `& 0x7fffffff` maskar bort teckenbiten â†’ garanterat icke-negativt
- `% M` mappar till index 0..M-1

### Bra vs DÃ¥liga Hashfunktioner

En bra hashfunktion:
1. Ã„r **deterministisk** (samma input â†’ samma output)
2. AnvÃ¤nder **alla delar** av nyckeln
3. **Sprider jÃ¤mnt** Ã¶ver hashtabellen

En dÃ¥lig hashfunktion: t.ex. bara fÃ¶rsta tecknet i en strÃ¤ng â†’ alla strÃ¤ngar som bÃ¶rjar med 'A' kolliderar.

---

# Del 5: Introduktion till Grafer (Avsnitt 4.1)

---

## ğŸŒ Vad Ã„r en Graf?

En **graf** Ã¤r en samling **hÃ¶rn** (vertices) fÃ¶rbundna med **kanter** (edges). Grafer modellerar *relationer* och *kopplingar* â€” och dyker upp Ã¶verallt:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GRAFER I VERKLIGHETEN                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  TillÃ¤mpning        â”‚  HÃ¶rn            â”‚  Kanter                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Socialt nÃ¤tverk    â”‚  AnvÃ¤ndare       â”‚  VÃ¤nskapsrelationer       â”‚
â”‚  Internet           â”‚  Routrar         â”‚  Fysiska anslutningar     â”‚
â”‚  Karta/GPS          â”‚  Korsningar      â”‚  VÃ¤gar                    â”‚
â”‚  SchemalÃ¤ggning     â”‚  Uppgifter       â”‚  Beroenden                â”‚
â”‚  Elektrisk krets    â”‚  Komponenter     â”‚  Ledningar                â”‚
â”‚  Biologi            â”‚  Arter           â”‚  Interaktioner            â”‚
â”‚  Kompilatorer       â”‚  Funktioner      â”‚  Funktionsanrop           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– GrundlÃ¤ggande Terminologi

**Graf G = (V, E):** V = mÃ¤ngden hÃ¶rn, E = mÃ¤ngden kanter.

**Grannskap (adjacency):** TvÃ¥ hÃ¶rn Ã¤r *grannar* om de fÃ¶rbinds av en kant.

**Grad (degree):** Antalet kanter som ansluter till ett hÃ¶rn.

**VÃ¤g (path):** En sekvens av hÃ¶rn fÃ¶rbundna av kanter. En *enkel* vÃ¤g besÃ¶ker inget hÃ¶rn mer Ã¤n en gÃ¥ng.

**Cykel:** En vÃ¤g som bÃ¶rjar och slutar i samma hÃ¶rn.

**SammanhÃ¤ngande (connected):** Det finns en vÃ¤g mellan varje par av hÃ¶rn.

**SammanhÃ¤ngande komponent (connected component):** En maximal sammanhÃ¤ngande delgraf.

**Acyklisk (acyclic):** En graf utan cykler. Ett acykliskt sammanhÃ¤ngande grafrum kallas **trÃ¤d**.

**Skog (forest):** En acyklisk graf (kan ha flera komponenter, vardera ett trÃ¤d).

```
  Exempelgraf (tinyG.txt):
  
  0 â€” 6          7 â€” 8        9 â€” 10
  |   |                       |  \
  1   4 â€” 5                  11 â€” 12
  |   |   |
  2   3 â€” 5
  
  13 hÃ¶rn, 13 kanter
  3 sammanhÃ¤ngande komponenter: {0,1,2,3,4,5,6}, {7,8}, {9,10,11,12}
```

**Nyckeltal:**
- **Gles graf (sparse):** E ~ V (vanligast i praktiken)
- **TÃ¤t graf (dense):** E ~ VÂ² (alla par fÃ¶rbundna)
- **TrÃ¤d med V hÃ¶rn:** Har exakt V-1 kanter

---

## ğŸ’¾ Grafrepresentation: Adjacency Lists

Tre alternativ finns, men boken (och vi) anvÃ¤nder **adjacenslista** (adjacency list):

### Tre MÃ¶jliga Representationer

| Representation | Plats | LÃ¤gg till kant | Kolla om v-w kant | Iterera grannar till v |
|---|---|---|---|---|
| Lista av kanter | E | O(1) | O(E) | O(E) |
| Adjacensmatris | VÂ² | O(1) | O(1) | O(V) |
| **Adjacenslistor** | **V + E** | **O(1)** | **O(degree(v))** | **O(degree(v))** |

**Adjacensmatris** (VÃ—V boolean-matris) slÃ¶sar minne: en graf med 1 miljon hÃ¶rn och 10 miljoner kanter behÃ¶ver 10â¶ Ã— 10â¶ = 10Â¹Â² bitar â‰ˆ 125 GB! Adjacenslistor behÃ¶ver bara ~10â· poster.

### Implementation: Graph

```java
public class Graph {
    private final int V;            // Antal hÃ¶rn
    private int E;                   // Antal kanter
    private Bag<Integer>[] adj;      // Adjacenslistor
    
    public Graph(int V) {
        this.V = V;
        this.E = 0;
        adj = (Bag<Integer>[]) new Bag[V];
        for (int v = 0; v < V; v++)
            adj[v] = new Bag<Integer>();  // Tom lista fÃ¶r varje hÃ¶rn
    }
    
    public void addEdge(int v, int w) {
        adj[v].add(w);   // LÃ¤gg till w i v:s lista
        adj[w].add(v);   // LÃ¤gg till v i w:s lista (oriktat â†’ dubbelriktat)
        E++;
    }
    
    public Iterable<Integer> adj(int v) {
        return adj[v];   // Alla grannar till v
    }
    
    public int V() { return V; }
    public int E() { return E; }
}
```

> ğŸ’¡ **Varje kant lagras TVÃ… gÃ¥nger** â€” en gÃ¥ng i varje Ã¤ndpunkts lista. Det Ã¤r nÃ¶dvÃ¤ndigt fÃ¶r att effektivt kunna iterera Ã¶ver grannar Ã¥t bÃ¥da hÃ¥ll.

**Adjacenslistor fÃ¶r tinyG.txt:**
```
  adj[]
  0: 6 â†’ 2 â†’ 1 â†’ 5          (ordningen beror pÃ¥ insÃ¤ttningsordning)
  1: 0
  2: 0
  3: 5 â†’ 4
  4: 5 â†’ 6 â†’ 3
  5: 3 â†’ 4 â†’ 0
  6: 0 â†’ 4
  7: 8
  8: 7
  ...
```

---

## ğŸ” Depth-First Search (DFS)

### IdÃ©n: Utforska SÃ¥ Djupt Som MÃ¶jligt

DFS Ã¤r inspirerad av TrÃ©maux's labyrintalgoritm: gÃ¥ framÃ¥t sÃ¥ lÃ¤nge du kan, backa nÃ¤r du stÃ¶ter pÃ¥ en Ã¥tervÃ¤ndsgrÃ¤nd eller ett redan besÃ¶kt hÃ¶rn.

```java
public class DepthFirstSearch {
    private boolean[] marked;  // marked[v] = sant om v Ã¤r besÃ¶kt
    private int count;         // Antal besÃ¶kta hÃ¶rn
    
    public DepthFirstSearch(Graph G, int s) {
        marked = new boolean[G.V()];
        dfs(G, s);
    }
    
    private void dfs(Graph G, int v) {
        marked[v] = true;      // Markera v som besÃ¶kt
        count++;
        for (int w : G.adj(v)) // FÃ¶r varje granne w till v:
            if (!marked[w])    //   Om w inte redan besÃ¶kt:
                dfs(G, w);     //     Utforska rekursivt!
    }
    
    public boolean marked(int v) { return marked[v]; }
    public int count() { return count; }
}
```

### Proposition A: DFS Prestanda

> **Proposition A:** DFS markerar alla hÃ¶rn fÃ¶rbundna med kÃ¤llan s, i tid proportionell mot summan av deras grader.

**Bevisskiss:** Varje hÃ¶rn besÃ¶ks hÃ¶gst en gÃ¥ng (tack vare `marked[]`). Varje kant undersÃ¶ks hÃ¶gst tvÃ¥ gÃ¥nger (en gÃ¥ng per Ã¤ndpunkt). Total tid: O(V + E) fÃ¶r hela den sammanhÃ¤ngande komponenten.

### Steg-fÃ¶r-steg SpÃ¥rning

```
  Graf:  0â€”2â€”1, 0â€”5, 2â€”3â€”5, 2â€”4, 3â€”4
  adj[]: 0:[2,1,5]  1:[0,2]  2:[0,1,3,4]  3:[5,4,2]  4:[3,2]  5:[3,0]
  
  dfs(0):
    markera 0
    â†’ granne 2 (ej markerad) â†’ dfs(2):
        markera 2
        â†’ granne 0 (markerad, skippa)
        â†’ granne 1 (ej markerad) â†’ dfs(1):
            markera 1
            â†’ granne 0 (markerad) â†’ skippa
            â†’ granne 2 (markerad) â†’ skippa
            â† KLAR med 1
        â†’ granne 3 (ej markerad) â†’ dfs(3):
            markera 3
            â†’ granne 5 (ej markerad) â†’ dfs(5):
                markera 5
                â†’ granne 3 (markerad) â†’ skippa
                â†’ granne 0 (markerad) â†’ skippa
                â† KLAR med 5
            â†’ granne 4 (ej markerad) â†’ dfs(4):
                markera 4
                â†’ granne 3 (markerad) â†’ skippa
                â†’ granne 2 (markerad) â†’ skippa
                â† KLAR med 4
            â†’ granne 2 (markerad) â†’ skippa
            â† KLAR med 3
        â†’ granne 4 (markerad) â†’ skippa
        â† KLAR med 2
    â†’ granne 1 (markerad) â†’ skippa
    â†’ granne 5 (markerad) â†’ skippa
    â† KLAR med 0
  
  BesÃ¶ksordning: 0, 2, 1, 3, 5, 4
```

---

## ğŸ›¤ï¸ DFS fÃ¶r VÃ¤gfinnning (DepthFirstPaths)

UtÃ¶ver att bara markera vilka hÃ¶rn som nÃ¥s, kan DFS hitta *vÃ¤gar*:

```java
public class DepthFirstPaths {
    private boolean[] marked;
    private int[] edgeTo;    // edgeTo[w] = v innebÃ¤r att vâ†’w var kanten
    private final int s;     // KÃ¤llhÃ¶rnet
    
    public DepthFirstPaths(Graph G, int s) {
        marked = new boolean[G.V()];
        edgeTo = new int[G.V()];
        this.s = s;
        dfs(G, s);
    }
    
    private void dfs(Graph G, int v) {
        marked[v] = true;
        for (int w : G.adj(v))
            if (!marked[w]) {
                edgeTo[w] = v;     // Kom ihÃ¥g: vi kom till w VIA v
                dfs(G, w);
            }
    }
    
    public boolean hasPathTo(int v) { return marked[v]; }
    
    public Iterable<Integer> pathTo(int v) {
        if (!hasPathTo(v)) return null;
        Stack<Integer> path = new Stack<>();
        for (int x = v; x != s; x = edgeTo[x])  // FÃ¶lj edgeTo[] bakÃ¥t
            path.push(x);
        path.push(s);
        return path;
    }
}
```

`edgeTo[]` bildar ett **trÃ¤d med rÃ¶tter i s** (parent-link representation). Varje hÃ¶rn pekar pÃ¥ det hÃ¶rn som "upptÃ¤ckte" det.

> âš ï¸ **OBS:** DFS hittar *en* vÃ¤g, men inte nÃ¶dvÃ¤ndigtvis den *kortaste* vÃ¤gen!

---

## ğŸŒŠ Breadth-First Search (BFS): Kortaste VÃ¤gar

### IdÃ©n: Utforska NivÃ¥ fÃ¶r NivÃ¥

Till skillnad frÃ¥n DFS (som dyker djupt) undersÃ¶ker BFS alla hÃ¶rn pÃ¥ avstÃ¥nd 1 fÃ¶rst, sedan avstÃ¥nd 2, etc. Detta garanterar att vi hittar den **kortaste vÃ¤gen** (i antal kanter).

BFS anvÃ¤nder en **kÃ¶** (FIFO) istÃ¤llet fÃ¶r rekursion (som implicit anvÃ¤nder en stack):

```java
public class BreadthFirstPaths {
    private boolean[] marked;
    private int[] edgeTo;
    private final int s;
    
    public BreadthFirstPaths(Graph G, int s) {
        marked = new boolean[G.V()];
        edgeTo = new int[G.V()];
        this.s = s;
        bfs(G, s);
    }
    
    private void bfs(Graph G, int s) {
        Queue<Integer> queue = new Queue<>();
        marked[s] = true;
        queue.enqueue(s);
        
        while (!queue.isEmpty()) {
            int v = queue.dequeue();         // Ta nÃ¤sta hÃ¶rn frÃ¥n kÃ¶n
            for (int w : G.adj(v)) {
                if (!marked[w]) {
                    edgeTo[w] = v;           // v upptÃ¤ckte w
                    marked[w] = true;        // Markera INNAN enqueue!
                    queue.enqueue(w);        // LÃ¤gg till i kÃ¶n
                }
            }
        }
    }
    
    // pathTo() och hasPathTo() â€” identiska med DFS-versionen
}
```

### DFS vs BFS: Visuell Skillnad

```
  DFS: Dyk djupt, backa vid Ã¥tervÃ¤ndsgrÃ¤nd     
  
  Steg:  0 â†’ 2 â†’ 1 (backa) â†’ 3 â†’ 5 (backa) â†’ 4
  VÃ¤g 0â†’5: 0-2-3-5  (lÃ¥ng, vindlande)
  
  BFS: Utforska i vÃ¥gor, nivÃ¥ fÃ¶r nivÃ¥          
  
  Steg:  0 â†’ {2,1,5} â†’ {3,4} â†’ {}
  VÃ¤g 0â†’5: 0-5  (kortast mÃ¶jlig!)
```

### Proposition B: BFS Ger Kortaste VÃ¤gar

> **Proposition B:** BFS berÃ¤knar kortaste vÃ¤gar (i antal kanter) frÃ¥n s till alla fÃ¶rbundna hÃ¶rn, i tid proportionell mot V + E.

### Generellt MÃ¶nster

DFS och BFS Ã¤r varianter av samma schema:

1. LÃ¤gg kÃ¤llhÃ¶rnet pÃ¥ en **datastruktur**
2. SÃ¥ lÃ¤nge datastrukturen ej tom:
   - Ta ut ett hÃ¶rn v
   - Markera v
   - LÃ¤gg in alla omarkerade grannar till v

Skillnaden: **DFS** anvÃ¤nder en **stack** (sist in, fÃ¶rst ut), **BFS** anvÃ¤nder en **kÃ¶** (fÃ¶rst in, fÃ¶rst ut).

---

## ğŸ§© Connected Components med DFS

Vi kan anvÃ¤nda DFS fÃ¶r att hitta *alla* sammanhÃ¤ngande komponenter:

```java
public class CC {
    private boolean[] marked;
    private int[] id;       // id[v] = komponent-ID fÃ¶r hÃ¶rn v
    private int count;      // Antal komponenter
    
    public CC(Graph G) {
        marked = new boolean[G.V()];
        id = new int[G.V()];
        for (int v = 0; v < G.V(); v++) {
            if (!marked[v]) {
                dfs(G, v);
                count++;     // Ny komponent upptÃ¤ckt!
            }
        }
    }
    
    private void dfs(Graph G, int v) {
        marked[v] = true;
        id[v] = count;      // Alla hÃ¶rn i samma DFS-sÃ¶kning fÃ¥r samma ID
        for (int w : G.adj(v))
            if (!marked[w])
                dfs(G, w);
    }
    
    public boolean connected(int v, int w) { return id[v] == id[w]; }
    public int id(int v) { return id[v]; }
    public int count() { return count; }
}
```

### Proposition C

> **Proposition C:** DFS-baserad CC anvÃ¤nder fÃ¶rbehandlingstid proportionell mot V + E och stÃ¶djer sedan `connected()`-frÃ¥gor i **O(1)**.

### DFS vs Union-Find fÃ¶r Connectivity

JÃ¤mfÃ¶rt med Union-Find (kap 1.5):

- **DFS (CC):** MÃ¥ste bygga hela grafen fÃ¶rst, sedan O(1) per frÃ¥ga. Kan Ã¤ven ge *vÃ¤gar*.
- **Union-Find:** Kan svara under pÃ¥gÃ¥ende konstruktion (online). Kan *inte* ge vÃ¤gar. Praktiskt snabbare om vi inte behÃ¶ver hela grafen.

---

## ğŸ“ Ytterligare Grafprocesseringsproblem (4.1)

Boken nÃ¤mner flera problem som lÃ¶ses med varianter av DFS:

**Cykeldetektering:** Finns det en cykel i grafen? â†’ DFS, kontrollera om vi hittar en granne som redan Ã¤r markerad (och inte Ã¤r vÃ¥r fÃ¶rÃ¤lder).

**TvÃ¥fÃ¤rgbarhet / Bipartiteness:** Kan vi fÃ¤rga hÃ¶rnen med 2 fÃ¤rger sÃ¥ att inga grannar har samma fÃ¤rg? â†’ DFS, fÃ¶rsÃ¶k alternera fÃ¤rger.

---

# ğŸ§  Propositioner att Komma IhÃ¥g

| Proposition | InnehÃ¥ll |
|---|---|
| **I** (2.2) | Undre grÃ¤ns: â‰¥ lg(N!) ~ N lg N jÃ¤mfÃ¶relser krÃ¤vs |
| **J** (2.2) | Mergesort Ã¤r asymptotiskt optimal (jÃ¤mfÃ¶relsebaserat) |
| **O** (2.4) | StÃ¶rsta nyckeln i heap-ordnat trÃ¤d finns i roten |
| **P** (2.4) | Komplett binÃ¤rtrÃ¤d med N noder har hÃ¶jd âŒŠlg NâŒ‹ |
| **Q** (2.4) | Heap: insert â‰¤ 1 + lg N, delMax â‰¤ 2 lg N jÃ¤mfÃ¶relser |
| **R** (2.4) | Heapkonstruktion med sink: < 2N jÃ¤mfÃ¶relser |
| **S** (2.4) | Heapsort: < 2N lg N + 2N jÃ¤mfÃ¶relser |
| **G** (3.3) | RÃ¶d-svart BST: hÃ¶jd â‰¤ 2 lg N |
| **H** (3.3) | RÃ¶d-svart BST: genomsnittlig vÃ¤g ~1.00 lg N |
| **I** (3.3) | RÃ¶d-svart BST: ALLA operationer O(lg N) i vÃ¤rsta fall |
| **A** (4.1) | DFS markerar alla fÃ¶rbundna hÃ¶rn i tid O(sum of degrees) |
| **B** (4.1) | BFS ger kortaste vÃ¤gar, i tid O(V + E) |
| **C** (4.1) | CC med DFS: O(V + E) fÃ¶rbehandling, O(1) frÃ¥gor |

---

## ğŸ¯ Minnesregel: HEAP-SORT

```
H - Heapkonstruktion med sink: O(N)
E - Extra minne: O(1) â€” in-place!
A - Alltid O(N lg N) â€” garanterad
P - PrioritetskÃ¶: hjÃ¤rtat i algoritmen
S - Sink & Swim: de tvÃ¥ primitiva operationerna
O - Optimal i BÃ…DE tid och minne (unik!)
R - Roten innehÃ¥ller alltid max
T - TrÃ¤dstruktur i en array (elegant!)
```

## ğŸ¯ Minnesregel: RÃ–D-SVART

```
R - RÃ¶da lÃ¤nkar lutar Ã¥t vÃ¤nster (left-leaning)
Ã– - Ã–verensstÃ¤mmer 1:1 med 2-3-trÃ¤d
D - Dubbel hÃ¶jd i vÃ¤rsta fall: â‰¤ 2 lg N
S - Samma get() som vanlig BST
V - Varje vÃ¤g: lika mÃ¥nga svarta lÃ¤nkar
A - Alla operationer logaritmiska (garanterat)
R - Rotationer + fÃ¤rgflippar balansar
T - Tre rader kod fixar allt i put()!
```

## ğŸ¯ Minnesregel: GRAF-DFS-BFS

```
G - Graf = hÃ¶rn + kanter
R - Representation med adjacenslistor: O(V+E) plats
A - Adjacency: granne-relation
F - Finns vÃ¤g? DFS svarar!

D - Djupt fÃ¶rst (stack/rekursion)
F - FÃ¶ljer kanter tills Ã¥tervÃ¤ndsgrÃ¤nd
S - Stack-baserad (implicit via rekursion)

B - Bredd fÃ¶rst (kÃ¶/FIFO)
F - Finner KORTASTE vÃ¤gen
S - Sveper nivÃ¥ fÃ¶r nivÃ¥
```

---

*Detta material Ã¤r baserat pÃ¥ "Algorithms, 4th Edition" av Robert Sedgewick och Kevin Wayne, samt fÃ¶relÃ¤sningsanteckningar av Jesper Larsson.*
